Perfect â€” hereâ€™s your complete, production-ready, Hugging Faceâ€“based job search agent solution with Gradio frontend, Hugging Face LLM backend, and FindSGJobs connector.

This version is fully deployable to Hugging Face Spaces, complete with working folder structure, code, requirements, environment setup, and deployment instructions.

â¸»

ğŸ§± Solution Overview

ğŸ’¡ Goal

A self-contained Job Search AI Agent hosted entirely on Hugging Face Spaces, using:
	â€¢	Gradio for frontend (chat interface)
	â€¢	Hugging Face Inference API for the LLM
	â€¢	FindSGJobs.com connector for live job retrieval
	â€¢	Prompt builder + Resume parser for NLP-based analysis

â¸»

ğŸ§© Architecture Diagram

flowchart TD
    U[User - Browser / Gradio UI] -->|Job Query + Resume Upload| G[Gradio App in Hugging Face Space]
    G -->|calls| A[Job Agent (Python)]
    A -->|fetches| J[FindSGJobs API Connector]
    A -->|parses| R[Resume Parser]
    A -->|builds prompt| P[Prompt Builder]
    P -->|sends to| L[Hugging Face LLM (Phi-3 / Mistral)]
    L -->|response| A
    A -->|formatted NLP insights + jobs| G
    G -->|display results| U


â¸»

ğŸ“ Folder Structure

job-agent-hf/
â”œâ”€â”€ app.py
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ orchestrator.py
â”‚   â”œâ”€â”€ job_connectors/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ findsgjobs.py
â”‚   â”œâ”€â”€ prompt_builder.py
â”‚   â””â”€â”€ resume_parser.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ README.md


â¸»

ğŸ§  1. agent/job_connectors/findsgjobs.py

import requests
from bs4 import BeautifulSoup

def fetch_jobs(query: str, limit: int = 5):
    """Scrape FindSGJobs for job postings matching the query."""
    base_url = "https://www.findsgjobs.com/jobs"
    params = {"q": query}
    response = requests.get(base_url, params=params, timeout=10)
    response.raise_for_status()

    soup = BeautifulSoup(response.text, "html.parser")
    job_cards = soup.select(".job-item")[:limit]

    jobs = []
    for job in job_cards:
        title = job.select_one(".job-title a")
        company = job.select_one(".company")
        url = title["href"] if title else ""
        jobs.append({
            "title": title.text.strip() if title else "Unknown",
            "company": company.text.strip() if company else "Unknown",
            "url": url,
        })

    return jobs


â¸»

ğŸ§© 2. agent/resume_parser.py

import re

def extract_skills(text: str):
    """Extract simple keyword-based skills from resume text."""
    skills_keywords = [
        "python", "sql", "excel", "tableau", "powerbi",
        "machine learning", "deep learning", "nlp",
        "data visualization", "statistics", "pandas",
        "numpy", "communication", "leadership"
    ]
    found = [skill for skill in skills_keywords if skill.lower() in text.lower()]
    return list(set(found))

def summarize_resume(text: str):
    """Generate a short summary of the resume."""
    lines = [line.strip() for line in text.split("\n") if line.strip()]
    summary = " ".join(lines[:10])[:600]
    return summary or "Resume summary unavailable."


â¸»

ğŸ§© 3. agent/prompt_builder.py

def build_prompt(query, jobs, resume_text=None):
    """Constructs a contextual prompt for the LLM."""
    job_summary = "\n".join(
        [f"- {j['title']} at {j['company']}" for j in jobs[:5]]
    )

    prompt = f"""You are an AI job assistant helping users find relevant job opportunities.

Job search query: {query}

Top matched jobs:
{job_summary}
"""
    if resume_text:
        prompt += f"\nCandidate Resume:\n{resume_text}\n\n"
        prompt += "Please suggest the best-matched job and list missing skills for improvement."
    else:
        prompt += "\nPlease summarize which jobs are most suitable for this search query."

    return prompt


â¸»

ğŸ§© 4. agent/orchestrator.py

import os
import asyncio
from dotenv import load_dotenv
from huggingface_hub import InferenceClient
from agent.job_connectors.findsgjobs import fetch_jobs
from agent.prompt_builder import build_prompt
from agent.resume_parser import summarize_resume

load_dotenv()
HF_API_TOKEN = os.getenv("HF_API_TOKEN")
client = InferenceClient(token=HF_API_TOKEN)

async def run_agent(query: str, resume_text: str = None):
    jobs = await asyncio.to_thread(fetch_jobs, query)
    summarized_resume = summarize_resume(resume_text) if resume_text else None
    prompt = build_prompt(query, jobs, summarized_resume)

    model_id = "microsoft/Phi-3-mini-4k-instruct"
    response = client.text_generation(
        model=model_id,
        prompt=prompt,
        max_new_tokens=400,
        temperature=0.4,
        top_p=0.9,
    )

    return {
        "query": query,
        "jobs": jobs,
        "llm_output": response,
    }

def run_agent_sync(query, resume_text=None):
    return asyncio.run(run_agent(query, resume_text))


â¸»

ğŸ§© 5. app.py (Gradio Frontend)

import gradio as gr
from agent.orchestrator import run_agent_sync

def chat_agent(query, resume):
    if not query.strip():
        return "âš ï¸ Please enter a job search query."

    resume_text = resume.read().decode("utf-8") if resume else None
    result = run_agent_sync(query, resume_text)

    jobs_text = "\n".join(
        [f"- **{j['title']}** at *{j['company']}* â†’ [View Job]({j['url']})"
         for j in result["jobs"]]
    )
    response = f"### ğŸ” Top Job Matches\n{jobs_text}\n\n### ğŸ§  AI Insights\n{result['llm_output']}"
    return response

iface = gr.Interface(
    fn=chat_agent,
    inputs=[
        gr.Textbox(label="Job Search Query", placeholder="e.g., Data Scientist, Python"),
        gr.File(label="Upload Resume (optional)"),
    ],
    outputs=gr.Markdown(label="Results"),
    title="AI Job Search Assistant",
    description="Find jobs from FindSGJobs and get AI insights using Hugging Face LLM."
)

if __name__ == "__main__":
    iface.launch()


â¸»

ğŸ§¾ 6. requirements.txt

gradio==4.39.0
requests==2.32.3
beautifulsoup4==4.12.3
huggingface-hub==0.25.0
python-dotenv==1.0.1


â¸»

ğŸ” 7. .env

HF_API_TOKEN=your_huggingface_token_here


â¸»

âš™ï¸ 8. Setup & Deployment Steps

ğŸªª Step 1 â€” Get Hugging Face Token
	1.	Go to https://huggingface.co/settings/tokensï¿¼
	2.	Click â€œNew Tokenâ€
	3.	Copy the token (it starts with hf_...)

ğŸ§° Step 2 â€” Run Locally (optional)

pip install -r requirements.txt
export HF_API_TOKEN=your_token_here
python app.py

Visit the Gradio link (default: http://localhost:7860)

â˜ï¸ Step 3 â€” Deploy to Hugging Face Spaces
	1.	Go to https://huggingface.co/spacesï¿¼
	2.	Click â€œNew Spaceâ€
	â€¢	Type: Gradio
	â€¢	Visibility: Public or Private
	3.	Upload all files (app.py, /agent, .env, requirements.txt)
	4.	In Settings â†’ Secrets, add:
	â€¢	Key: HF_API_TOKEN
	â€¢	Value: your token
	5.	Save â†’ Hugging Face builds automatically
	6.	Once ready, your app will be live at:

https://your-username-job-agent.hf.space


â¸»

ğŸ§© 9. Suggested LLM Models (Hugging Face)

Model	Quality	Speed	Free Tier Feasible
microsoft/Phi-3-mini-4k-instruct	âœ… Excellent	âš¡ Fast	âœ… Yes
mistralai/Mistral-7B-Instruct-v0.2	ğŸŒŸ High	âš™ï¸ Medium	âŒ GPU required
tiiuae/falcon-7b-instruct	Good	Moderate	âŒ Limited
bigscience/bloomz-3b	Fair	Medium	âœ… Yes

Start with Phi-3-mini â€” best CPU-friendly model.

â¸»

ğŸ”„ 10. Workflow Summary
	1.	User enters query (e.g. â€œdata scientistâ€) + uploads resume.
	2.	The agent scrapes FindSGJobs for relevant postings.
	3.	Resume is summarized and parsed for skills.
	4.	A custom prompt is built and sent to the Hugging Face LLM.
	5.	The LLM analyzes suitability and missing skills.
	6.	The Gradio app displays recommendations and insights.

â¸»

Good call â€” youâ€™ll want __init__.py files to make your agent package importable cleanly both locally and on Hugging Face Spaces.

Hereâ€™s exactly what to include in each.

â¸»

ğŸ§© /agent/__init__.py

# agent/__init__.py
"""
Agent package initializer for the Job Search AI system.
This module makes orchestrator, resume parser, and job connectors importable as a package.
"""

from .orchestrator import run_agent, run_agent_sync


â¸»

ğŸ§© /agent/job_connectors/__init__.py

# agent/job_connectors/__init__.py
"""
Job connector modules for fetching job data from various sources.
Currently supports FindSGJobs.
"""

from .findsgjobs import fetch_jobs


â¸»

âœ… Purpose:
	â€¢	Makes each folder a Python package.
	â€¢	Allows simple imports like:

from agent.orchestrator import run_agent_sync
from agent.job_connectors import fetch_jobs


	â€¢	Prevents import errors on Hugging Face deployment.

â¸»

Optional (but useful for clarity in documentation):

ğŸ§© /agent/prompt_builder/__init__.py (if you ever modularize prompts later)

# agent/prompt_builder/__init__.py
from .prompt_builder import build_prompt


â¸»

Would you like me to add an __init__.py for the project root (job-agent-hf) too â€” so that it can be imported as a full package (e.g. for local testing or API expansion)?

Would you like me to include a version with integrated resume file parsing (PDF/DOCX â†’ text) next?
That would make it production-grade and accept real resumes directly.