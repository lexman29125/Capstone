{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZSTA4NqD1_v",
        "outputId": "26b59b21-bdba-4855-acad-53b1cf4da9cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting job application workflow...\n",
            "üöÄ CoordinatorAgent 'root_agent' initiating job search for 'Senior Software Engineer - Cloud' and application process for candidate 'Alice Wonderland'...\n",
            "‚öôÔ∏è Delegating job search to job_search_agent...\n",
            "üîé Job search complete. Found 5 jobs:\n",
            "- üíº Product Manager - Senior Software Engineer - Cloud at Innovate Co. (Salary: $140,000)\n",
            "- üíº UX Designer - Senior Software Engineer - Cloud at Creative Hub (Salary: $110,000)\n",
            "- üíº Data Scientist - Senior Software Engineer - Cloud at Data Inc. (Salary: $130,000)\n",
            "- üíº DevOps Engineer - Senior Software Engineer - Cloud at Cloud Solutions (Salary: $125,000)\n",
            "- üíº Software Engineer - Senior Software Engineer - Cloud at Tech Corp (Salary: $120,000)\n",
            "‚úÖ Selected job based on skills and salary expectations: 'Data Scientist - Senior Software Engineer - Cloud' at 'Data Inc.' (Score: 30).\n",
            "üì¨ Delegating application submission to candidate_agent for job ID JOB-3595...\n",
            "üéâ Application submission status: success. Message: Application for job JOB-3595 submitted.\n",
            "Job application workflow completed.\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "import nest_asyncio\n",
        "import random\n",
        "import re # Import regex for salary parsing\n",
        "\n",
        "# Ensure nest_asyncio is applied if not already done in the session\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Assuming Tool, Agent are defined in previous cells and are available in scope.\n",
        "# Re-defining them here for clarity in this single block if notebook state is reset\n",
        "class Tool:\n",
        "    def __init__(self, func, name, description):\n",
        "        self.func = func\n",
        "        self.name = name\n",
        "        self.description = description\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, name, instruction, tools: list):\n",
        "        self.name = name\n",
        "        self.instruction = instruction\n",
        "        self.tools = tools\n",
        "\n",
        "# Helper function to parse salary from string\n",
        "def parse_salary(salary_str: str) -> int:\n",
        "    if not salary_str: return 0\n",
        "    # Remove non-numeric characters except comma, then remove comma, then convert to int\n",
        "    numeric_str = re.sub(r'[^\\\\d,]', '', salary_str)\n",
        "    numeric_str = numeric_str.replace(',', '')\n",
        "    try:\n",
        "        return int(numeric_str)\n",
        "    except ValueError:\n",
        "        return 0\n",
        "\n",
        "# Re-create dummy functions for independent execution of this cell if needed\n",
        "def job_search(query: str, max_results: int = 5) -> list:\n",
        "    sample_jobs = [\n",
        "        {\"title\": f\"Software Engineer - {query}\", \"company\": \"Tech Corp\", \"location\": \"San Francisco, CA\", \"description\": \"Develop and maintain software, good with Python, Cloud.\", \"salary\": \"$120,000\"},\n",
        "        {\"title\": f\"Data Scientist - {query}\", \"company\": \"Data Inc.\", \"location\": \"New York, NY\", \"description\": \"Analyze large datasets, using AI/ML, good with Python.\", \"salary\": \"$130,000\"},\n",
        "        {\"title\": f\"Product Manager - {query}\", \"company\": \"Innovate Co.\", \"location\": \"Seattle, WA\", \"description\": \"Define product vision and roadmap.\", \"salary\": \"$140,000\"},\n",
        "        {\"title\": f\"UX Designer - {query}\", \"company\": \"Creative Hub\", \"location\": \"Austin, TX\", \"description\": \"Design user interfaces, on Cloud platforms.\", \"salary\": \"$110,000\"},\n",
        "        {\"title\": f\"DevOps Engineer - {query}\", \"company\": \"Cloud Solutions\", \"location\": \"Remote\", \"description\": \"Manage infrastructure and deployments on Cloud.\", \"salary\": \"$125,000\"}\n",
        "    ]\n",
        "    random.shuffle(sample_jobs)\n",
        "    return sample_jobs[:max_results]\n",
        "\n",
        "def submit_application(job_id: str, candidate_profile: dict) -> dict:\n",
        "    if random.random() < 0.9:\n",
        "        return {\"status\": \"success\", \"message\": f\"Application for job {job_id} submitted.\", \"job_id\": job_id, \"candidate_name\": candidate_profile.get('name')}\n",
        "    else:\n",
        "        return {\"status\": \"failure\", \"message\": f\"Failed to submit application for job {job_id}.\", \"job_id\": job_id, \"candidate_name\": candidate_profile.get('name')}\n",
        "\n",
        "# Re-create Tool instances\n",
        "job_search_tool = Tool(\n",
        "    func=job_search,\n",
        "    name=\"job_search\",\n",
        "    description=\"Searches for job listings based on a query and returns a list of job details.\"\n",
        ")\n",
        "submit_application_tool = Tool(\n",
        "    func=submit_application,\n",
        "    name=\"submit_application\",\n",
        "    description=\"Submits a job application with a given job ID and candidate profile.\"\n",
        ")\n",
        "\n",
        "# Re-create Agent instances\n",
        "job_search_agent = Agent(\n",
        "    name=\"job_search_agent\",\n",
        "    instruction=\"I search for jobs based on a given query.\",\n",
        "    tools=[job_search_tool]\n",
        ")\n",
        "candidate_agent = Agent(\n",
        "    name=\"candidate_agent\",\n",
        "    instruction=\"I manage candidate profiles and submit job applications.\",\n",
        "    tools=[submit_application_tool]\n",
        ")\n",
        "\n",
        "# Redefine CoordinatorAgent with the full run_live method (job selection and error handling)\n",
        "class CoordinatorAgent(Agent):\n",
        "    def __init__(self, name: str, instruction: str, tools: list = None, sub_agents: list = None):\n",
        "        super().__init__(name, instruction, tools if tools is not None else [])\n",
        "        self.sub_agents = sub_agents if sub_agents is not None else []\n",
        "\n",
        "    async def run_live(self, query: str, candidate_profile: dict):\n",
        "        yield f\"üöÄ CoordinatorAgent '{self.name}' initiating job search for '{query}' and application process for candidate '{candidate_profile.get('name')}'...\"\n",
        "\n",
        "        # 2a. Find the job_search_agent\n",
        "        job_search_agent_found = next((agent for agent in self.sub_agents if agent.name == \"job_search_agent\"), None)\n",
        "        if not job_search_agent_found:\n",
        "            yield \"‚ùå Error: job_search_agent not found.\"\n",
        "            return\n",
        "        job_search_tool_instance = next((tool for tool in job_search_agent_found.tools if tool.name == \"job_search\"), None)\n",
        "        if not job_search_tool_instance:\n",
        "            yield \"‚ùå Error: job_search tool not found for job_search_agent.\"\n",
        "            return\n",
        "\n",
        "        # 2b. Simulate job_search_agent using its job_search_tool with error handling\n",
        "        yield f\"‚öôÔ∏è Delegating job search to {job_search_agent_found.name}...\"\n",
        "        jobs = []\n",
        "        try:\n",
        "            jobs = job_search_tool_instance.func(query, max_results=5) # Increased max_results to have more options\n",
        "        except Exception as e:\n",
        "            yield f\"‚ùå Error during job search: {e}\"\n",
        "            return\n",
        "\n",
        "        # 2c. Yield message about jobs found\n",
        "        yield f\"üîé Job search complete. Found {len(jobs)} jobs:\" \\\n",
        "              + \"\\n\" + \"\\n\".join([f\"- üíº {job['title']} at {job['company']} (Salary: {job.get('salary', 'N/A')})\" for job in jobs])\n",
        "\n",
        "        if not jobs:\n",
        "            yield \"‚ö†Ô∏è No jobs found, unable to apply.\"\n",
        "            return\n",
        "\n",
        "        # 2d. Enhanced Job Selection Logic\n",
        "        candidate_skills = [s.lower() for s in candidate_profile.get('skills', [])]\n",
        "        salary_expectation = candidate_profile.get('salary_expectation', 0)\n",
        "\n",
        "        def score_job(job: dict) -> int:\n",
        "            score = 0\n",
        "            job_text = (job.get('title', '') + ' ' + job.get('description', '')).lower()\n",
        "            job_salary = parse_salary(job.get('salary', ''))\n",
        "\n",
        "            # Skill matching\n",
        "            matched_skills_count = sum(1 for skill in candidate_skills if skill in job_text)\n",
        "            score += matched_skills_count * 10 # Each skill match adds 10 points\n",
        "\n",
        "            # Salary matching\n",
        "            if job_salary >= salary_expectation:\n",
        "                score += 5 # Meeting salary expectation adds 5 points\n",
        "\n",
        "            # Prioritize 'Senior Engineer' in title if specifically searched for and available\n",
        "            if \"senior engineer\" in job.get('title', '').lower() and \"senior engineer\" in query.lower():\n",
        "                score += 2 # Small boost for direct title match\n",
        "\n",
        "            return score\n",
        "\n",
        "        scored_jobs = []\n",
        "        for job in jobs:\n",
        "            scored_jobs.append((score_job(job), job))\n",
        "\n",
        "        # Sort by score in descending order\n",
        "        scored_jobs.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "        selected_job = None\n",
        "        if scored_jobs and scored_jobs[0][0] > 0: # If at least one job has a positive score\n",
        "            selected_job = scored_jobs[0][1]\n",
        "            yield f\"‚úÖ Selected job based on skills and salary expectations: '{selected_job['title']}' at '{selected_job['company']}' (Score: {scored_jobs[0][0]}).\"\n",
        "        else: # Fallback if no job scores positively or scored_jobs is empty\n",
        "            # Original fallback logic: try to find a 'Senior Engineer' job or take the first one\n",
        "            selected_job = next((job for job in jobs if \"Senior Engineer\" in job['title']), jobs[0])\n",
        "            yield f\"‚ö†Ô∏è No jobs matched criteria strongly. Falling back to default selection: '{selected_job['title']}' at '{selected_job['company']}' (Score: 0).\"\n",
        "\n",
        "        # Assign a dummy job_id for demonstration\n",
        "        job_id = f\"JOB-{random.randint(1000, 9999)}\"\n",
        "\n",
        "        # 2e. Find the candidate_agent\n",
        "        candidate_agent_found = next((agent for agent in self.sub_agents if agent.name == \"candidate_agent\"), None)\n",
        "        if not candidate_agent_found:\n",
        "            yield \"‚ùå Error: candidate_agent not found.\"\n",
        "            return\n",
        "        submit_application_tool_instance = next((tool for tool in candidate_agent_found.tools if tool.name == \"submit_application\"), None)\n",
        "        if not submit_application_tool_instance:\n",
        "            yield \"‚ùå Error: submit_application tool not found for candidate_agent.\"\n",
        "            return\n",
        "\n",
        "        # 2f. Simulate candidate_agent using its submit_application_tool with error handling\n",
        "        yield f\"üì¨ Delegating application submission to {candidate_agent_found.name} for job ID {job_id}...\"\n",
        "        application_status = {}\n",
        "        try:\n",
        "            application_status = submit_application_tool_instance.func(job_id, candidate_profile)\n",
        "        except Exception as e:\n",
        "            yield f\"‚ùå Error during application submission: {e}\"\n",
        "            return\n",
        "\n",
        "        # 2g. Yield application submission status\n",
        "        yield f\"üéâ Application submission status: {application_status.get('status', 'unknown')}. Message: {application_status.get('message', 'An unknown error occurred.')}\"\n",
        "\n",
        "\n",
        "# Re-instantiate the CoordinatorAgent with the new class definition\n",
        "root_agent = CoordinatorAgent(\n",
        "    name=\"root_agent\",\n",
        "    instruction=\"I orchestrate the job search and application process by coordinating between the job search and candidate agents to find suitable jobs and submit applications.\",\n",
        "    sub_agents=[job_search_agent, candidate_agent]\n",
        ")\n",
        "\n",
        "# Sample data for direct execution\n",
        "sample_candidate_profile = {\n",
        "    \"name\": \"Alice Wonderland\",\n",
        "    \"email\": \"alice@example.com\",\n",
        "    \"resume_link\": \"https://example.com/alice_resume.pdf\",\n",
        "    \"experience\": \"10+ years as Software Engineer, 5 years in Cloud Architecture\",\n",
        "    \"skills\": [\"Python\", \"Cloud\", \"AI/ML\", \"Data Analysis\", \"DevOps\"],\n",
        "    \"salary_expectation\": 135000\n",
        "}\n",
        "sample_job_query = \"Senior Software Engineer - Cloud\"\n",
        "\n",
        "async def run_workflow_without_streamlit(job_query, candidate_profile):\n",
        "    print(\"Starting job application workflow...\")\n",
        "    async for step_output in root_agent.run_live(job_query, candidate_profile):\n",
        "        print(step_output)\n",
        "    print(\"Job application workflow completed.\")\n",
        "\n",
        "# Run the workflow\n",
        "if __name__ == '__main__':\n",
        "    # Ensure an event loop is running. nest_asyncio.apply() usually handles this for Colab.\n",
        "    asyncio.run(run_workflow_without_streamlit(sample_job_query, sample_candidate_profile))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84d010b1"
      },
      "source": [
        "# Task\n",
        "Create a new workflow that analyzes a candidate's resume against a job description to identify skills gaps. This workflow should use the Gemini 2.5 Flash model for analysis and replace the previous job search and application submission functionality. Provide a dummy `resume_path` and `job_url` to demonstrate the new workflow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20308e9e"
      },
      "source": [
        "## Add necessary imports and LLM setup\n",
        "\n",
        "### Subtask:\n",
        "In the new cell, add imports for PDF processing libraries (e.g., `PyPDF2` or `fitz`), web scraping (e.g., `requests`, `BeautifulSoup`), and initialize the `google.generativeai` client with the Gemini 2.5 Flash model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47c30681",
        "outputId": "aec0320d-010a-4e59-b883-903457bb22fc"
      },
      "source": [
        "!pip install PyPDF2\n",
        "print(\"PyPDF2 installed successfully.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "PyPDF2 installed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0ccdfef"
      },
      "source": [
        "**Reasoning**:\n",
        "Since PyPDF2 is now installed, I need to re-run the code block that imports all necessary libraries and initializes the Google Generative AI client, as this was the original intent of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "cd195be6",
        "outputId": "642799e3-86d0-4d4d-f2dd-6284bd5c4fc0"
      },
      "source": [
        "import google.generativeai as gen\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import PyPDF2\n",
        "import os\n",
        "\n",
        "# Configure the Google Generative AI client\n",
        "# Make sure to set your GOOGLE_API_KEY in your environment variables or provide it when prompted.\n",
        "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
        "\n",
        "if not GOOGLE_API_KEY or GOOGLE_API_KEY == \"YOUR_GOOGLE_API_KEY_HERE\":\n",
        "    print(\"GOOGLE_API_KEY environment variable not set or is a placeholder.\")\n",
        "    print(\"Please provide your Google API Key to continue.\")\n",
        "    GOOGLE_API_KEY = input(\"Enter your Google API Key: \").strip()\n",
        "\n",
        "    # Optionally, set it as an environment variable for subsequent runs in this session\n",
        "    if GOOGLE_API_KEY:\n",
        "        os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "    else:\n",
        "        raise ValueError(\"Google API Key is required but was not provided.\")\n",
        "\n",
        "gen.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "llm_model = None\n",
        "tried_model_names = ['gemini-1.5-flash', 'gemini-pro', 'gemini-1.0-pro']\n",
        "\n",
        "for model_name in tried_model_names:\n",
        "    try:\n",
        "        llm_model = gen.get_model(model_name)\n",
        "        print(f\"Successfully loaded LLM model: {llm_model.name}\")\n",
        "        break # Exit loop if a model is successfully loaded\n",
        "    except Exception as e:\n",
        "        print(f\"WARNING: Could not load model '{model_name}': {e}\")\n",
        "\n",
        "if not llm_model:\n",
        "    print(\"Attempting to list available models to find an alternative...\")\n",
        "    try:\n",
        "        # Filter for models that support text generation\n",
        "        available_generative_models = [m.name for m in gen.list_models() if \"generateContent\" in m.supported_generation_methods]\n",
        "        if available_generative_models:\n",
        "            print(f\"Available generative models: {', '.join(available_generative_models)}\")\n",
        "            # Try to pick the first available generative model as a fallback\n",
        "            fallback_model_name = available_generative_models[0]\n",
        "            print(f\"Attempting to load fallback model: {fallback_model_name}\")\n",
        "            llm_model = gen.get_model(fallback_model_name)\n",
        "            print(f\"Successfully loaded fallback LLM model: {llm_model.name}\")\n",
        "        else:\n",
        "            raise ValueError(\"No generative models found with the provided API key that support 'generateContent'.\")\n",
        "    except Exception as list_e:\n",
        "        raise ValueError(f\"Error listing models or no fallback model found: {list_e}. Please check your API key and region settings for Google Generative AI access.\")\n",
        "\n",
        "if llm_model:\n",
        "    print(\"Imports and Google Generative AI client configured successfully.\")\n",
        "else:\n",
        "    raise ValueError(\"Failed to load any LLM model after multiple attempts. Please ensure your GOOGLE_API_KEY is valid and has access to Google Generative AI models in your region.\")\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:404 GET /v1beta/models/gemini-1.5-flash?%24alt=json%3Benum-encoding%3Dint (::1) 533.73ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Could not load model 'gemini-1.5-flash': 404 GET https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash?%24alt=json%3Benum-encoding%3Dint: Model is not found: models/gemini-1.5-flash for api version v1beta\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:404 GET /v1beta/models/gemini-pro?%24alt=json%3Benum-encoding%3Dint (::1) 203.73ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Could not load model 'gemini-pro': 404 GET https://generativelanguage.googleapis.com/v1beta/models/gemini-pro?%24alt=json%3Benum-encoding%3Dint: Model is not found: models/gemini-pro for api version v1beta\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:404 GET /v1beta/models/gemini-1.0-pro?%24alt=json%3Benum-encoding%3Dint (::1) 254.16ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Could not load model 'gemini-1.0-pro': 404 GET https://generativelanguage.googleapis.com/v1beta/models/gemini-1.0-pro?%24alt=json%3Benum-encoding%3Dint: Model is not found: models/gemini-1.0-pro for api version v1beta\n",
            "Attempting to list available models to find an alternative...\n",
            "Available generative models: models/gemini-2.5-pro-preview-03-25, models/gemini-2.5-flash-preview-05-20, models/gemini-2.5-flash, models/gemini-2.5-flash-lite-preview-06-17, models/gemini-2.5-pro-preview-05-06, models/gemini-2.5-pro-preview-06-05, models/gemini-2.5-pro, models/gemini-2.0-flash-exp, models/gemini-2.0-flash, models/gemini-2.0-flash-001, models/gemini-2.0-flash-exp-image-generation, models/gemini-2.0-flash-lite-001, models/gemini-2.0-flash-lite, models/gemini-2.0-flash-preview-image-generation, models/gemini-2.0-flash-lite-preview-02-05, models/gemini-2.0-flash-lite-preview, models/gemini-2.0-pro-exp, models/gemini-2.0-pro-exp-02-05, models/gemini-exp-1206, models/gemini-2.0-flash-thinking-exp-01-21, models/gemini-2.0-flash-thinking-exp, models/gemini-2.0-flash-thinking-exp-1219, models/gemini-2.5-flash-preview-tts, models/gemini-2.5-pro-preview-tts, models/learnlm-2.0-flash-experimental, models/gemma-3-1b-it, models/gemma-3-4b-it, models/gemma-3-12b-it, models/gemma-3-27b-it, models/gemma-3n-e4b-it, models/gemma-3n-e2b-it, models/gemini-flash-latest, models/gemini-flash-lite-latest, models/gemini-pro-latest, models/gemini-2.5-flash-lite, models/gemini-2.5-flash-image-preview, models/gemini-2.5-flash-image, models/gemini-2.5-flash-preview-09-2025, models/gemini-2.5-flash-lite-preview-09-2025, models/gemini-robotics-er-1.5-preview, models/gemini-2.5-computer-use-preview-10-2025\n",
            "Attempting to load fallback model: models/gemini-2.5-pro-preview-03-25\n",
            "Successfully loaded fallback LLM model: models/gemini-2.5-pro-preview-03-25\n",
            "Imports and Google Generative AI client configured successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab77824c"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous steps successfully loaded an LLM model, completing the initial setup part of the subtask. Now, I need to define a function to read the text content from a PDF resume using the `PyPDF2` library that was previously imported and installed. This is a prerequisite for analyzing the resume against a job description, which is the core of the new workflow.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82f6aad1",
        "outputId": "0e24c18c-d90d-459e-8f3a-4a1f61c9cfcb"
      },
      "source": [
        "def extract_text_from_pdf(pdf_path: str) -> str:\n",
        "    \"\"\"Extracts text from a local PDF file.\"\"\"\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            text = ''\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading PDF: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "print(\"PDF text extraction function defined.\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF text extraction function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1bf1ca4"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step defined a function to extract text from a PDF. Now, to analyze a resume against a job description from a URL, I need to define a function that can scrape text content from a given web page. This function will utilize `requests` for fetching the page and `BeautifulSoup` for parsing the HTML and extracting the relevant text, aligning with the subtask's requirement for web scraping.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae39e48c",
        "outputId": "8166a3bb-0847-40d5-a72d-58d571254972"
      },
      "source": [
        "def extract_text_from_url(url: str) -> str:\n",
        "    \"\"\"Extracts text content from a given URL, typically for a job description.\"\"\"\n",
        "    try:\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Remove script and style elements\n",
        "        for script_or_style in soup(['script', 'style']):\n",
        "            script_or_style.extract()\n",
        "\n",
        "        # Get text and clean it\n",
        "        text = soup.get_text()\n",
        "        lines = (line.strip() for line in text.splitlines())\n",
        "        # Break multi-headlines into a line each\n",
        "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
        "        # Drop blank lines\n",
        "        text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
        "        return text\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching URL {url}: {e}\")\n",
        "        return \"\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing URL {url}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "print(\"Web scraping function for job descriptions defined.\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Web scraping function for job descriptions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e04eb2d"
      },
      "source": [
        "## Define placeholder for user inputs\n",
        "\n",
        "### Subtask:\n",
        "Create variables for `resume_path` and `job_url` to simulate user input for the new workflow.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91d63539"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to define two placeholder variables, `resume_path` and `job_url`, with dummy values and add comments as instructed to simulate user input for the new workflow.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be920017",
        "outputId": "ed822f6e-7a35-4403-9986-6d0ef0cc2e2f"
      },
      "source": [
        "resume_path = \"dummy_resume.pdf\"  # Placeholder: Replace with the actual path to your PDF resume file.\n",
        "job_url = \"https://example.com/job_description\"  # Placeholder: Replace with the actual URL of the job description.\n",
        "\n",
        "print(f\"Dummy resume_path set to: {resume_path}\")\n",
        "print(f\"Dummy job_url set to: {job_url}\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy resume_path set to: dummy_resume.pdf\n",
            "Dummy job_url set to: https://example.com/job_description\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fd6e5f2"
      },
      "source": [
        "## Update Agent and Tool Definitions\n",
        "\n",
        "### Subtask:\n",
        "Modify the `Agent` and `Tool` classes if necessary for the new workflow. Remove the `job_search_tool`, `job_search_agent`, and `submit_application_tool` as they are no longer needed. Introduce a new tool for `candidate_agent` for resume and job description analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80252e89"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to update the agent and tool definitions by removing the old job search and application submission tools and agents, then creating a new analysis tool and re-instantiating the candidate agent with this new tool.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ec20f91",
        "outputId": "db1a4169-32e0-486e-e119-cd17fcf59db6"
      },
      "source": [
        "import asyncio\n",
        "import nest_asyncio\n",
        "import random\n",
        "import re # Import regex for salary parsing\n",
        "\n",
        "# Ensure nest_asyncio is applied if not already done in the session\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Assuming Tool, Agent are defined in previous cells and are available in scope.\n",
        "# Re-defining them here for clarity in this single block if notebook state is reset\n",
        "class Tool:\n",
        "    def __init__(self, func, name, description):\n",
        "        self.func = func\n",
        "        self.name = name\n",
        "        self.description = description\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, name, instruction, tools: list):\n",
        "        self.name = name\n",
        "        self.instruction = instruction\n",
        "        self.tools = tools\n",
        "\n",
        "# Helper function to parse salary from string\n",
        "def parse_salary(salary_str: str) -> int:\n",
        "    if not salary_str: return 0\n",
        "    # Remove non-numeric characters except comma, then remove comma, then convert to int\n",
        "    numeric_str = re.sub(r'[^\\\\d,]', '', salary_str)\n",
        "    numeric_str = numeric_str.replace(',', '')\n",
        "    try:\n",
        "        return int(numeric_str)\n",
        "    except ValueError:\n",
        "        return 0\n",
        "\n",
        "# Placeholder for the new analysis function\n",
        "def analyze_resume_job_description_placeholder(resume_text: str, job_description_text: str) -> dict:\n",
        "    \"\"\"Placeholder function for resume and job description analysis.\"\"\"\n",
        "    print(f\"Analyzing resume (length: {len(resume_text)}) and job description (length: {len(job_description_text)}).\")\n",
        "    return {\"analysis_status\": \"success\", \"message\": \"Analysis not yet implemented, but placeholder executed.\", \"skills_match\": \"N/A\", \"gaps\": \"N/A\"}\n",
        "\n",
        "# 1. No modifications to Tool and Agent class structures are needed at this stage.\n",
        "\n",
        "# 2. Remove instantiation of old tools and agents.\n",
        "# job_search_tool, submit_application_tool, job_search_agent, and the original candidate_agent are removed.\n",
        "\n",
        "# 3. Define a new Tool instance for analysis.\n",
        "analysis_tool = Tool(\n",
        "    func=analyze_resume_job_description_placeholder,\n",
        "    name=\"analyze_resume_job_description\",\n",
        "    description=\"Analyzes a candidate's resume against a job description to identify skills and gaps.\"\n",
        ")\n",
        "\n",
        "# 4. Re-instantiate the candidate_agent with the new analysis_tool.\n",
        "candidate_agent = Agent(\n",
        "    name=\"candidate_agent\",\n",
        "    instruction=\"I manage candidate profiles and analyze resumes against job descriptions.\",\n",
        "    tools=[analysis_tool]\n",
        ")\n",
        "\n",
        "# Redefine CoordinatorAgent to reflect new workflow\n",
        "class CoordinatorAgent(Agent):\n",
        "    def __init__(self, name: str, instruction: str, tools: list = None, sub_agents: list = None):\n",
        "        super().__init__(name, instruction, tools if tools is not None else [])\n",
        "        self.sub_agents = sub_agents if sub_agents is not None else []\n",
        "\n",
        "    async def run_live(self, resume_text: str, job_description_text: str):\n",
        "        yield f\"üöÄ CoordinatorAgent '{self.name}' initiating resume and job description analysis...\"\n",
        "\n",
        "        candidate_agent_found = next((agent for agent in self.sub_agents if agent.name == \"candidate_agent\"), None)\n",
        "        if not candidate_agent_found:\n",
        "            yield \"‚ùå Error: candidate_agent not found.\"\n",
        "            return\n",
        "\n",
        "        analysis_tool_instance = next((tool for tool in candidate_agent_found.tools if tool.name == \"analyze_resume_job_description\"), None)\n",
        "        if not analysis_tool_instance:\n",
        "            yield \"‚ùå Error: analyze_resume_job_description tool not found for candidate_agent.\"\n",
        "            return\n",
        "\n",
        "        yield f\"‚öôÔ∏è Delegating analysis to {candidate_agent_found.name} using {analysis_tool_instance.name} tool...\"\n",
        "        try:\n",
        "            analysis_result = analysis_tool_instance.func(resume_text, job_description_text)\n",
        "            yield f\"‚úÖ Analysis complete: {analysis_result.get('message', 'No message provided.')} Status: {analysis_result.get('analysis_status', 'unknown')}\"\n",
        "        except Exception as e:\n",
        "            yield f\"‚ùå Error during analysis: {e}\"\n",
        "            return\n",
        "\n",
        "# Re-instantiate the CoordinatorAgent with the new class definition and updated sub-agents\n",
        "root_agent = CoordinatorAgent(\n",
        "    name=\"root_agent\",\n",
        "    instruction=\"I orchestrate the resume and job description analysis process.\",\n",
        "    sub_agents=[candidate_agent]\n",
        ")\n",
        "\n",
        "print(\"Agent and Tool definitions updated for new workflow.\")\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent and Tool definitions updated for new workflow.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a493a18e"
      },
      "source": [
        "## Implement Resume Processing and Job Description Fetching\n",
        "\n",
        "### Subtask:\n",
        "Extract text from the dummy PDF resume and fetch text from the dummy job description URL using the previously defined helper functions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcd0728e"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code blocks defined helper functions for PDF and URL text extraction. Now, I need to implement the first instruction of the subtask, which is to create a dummy PDF file. Since direct file creation with content is not directly supported in the notebook environment without specific libraries, I will install `reportlab` to programmatically create a PDF with dummy content. This library allows generating PDF files from Python code.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ab95ccb",
        "outputId": "fa7e3947-1394-45e5-ffef-9745199b606c"
      },
      "source": [
        "import os\n",
        "#!pip install reportlab\n",
        "\n",
        "print(\"reportlab installed successfully.\")\n",
        "\n",
        "# Create a dummy PDF file named dummy_resume.pdf\n",
        "# This is necessary because the previous `resume_path` pointed to a non-existent file.\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.pagesizes import letter\n",
        "\n",
        "def create_dummy_pdf(filename=\"dummy_resume.pdf\", content=\"\"):\n",
        "    c = canvas.Canvas(filename, pagesize=letter)\n",
        "    textobject = c.beginText()\n",
        "    textobject.setTextOrigin(10, 750) # Set starting position\n",
        "    textobject.setFont(\"Helvetica\", 12) # Set font and size\n",
        "\n",
        "    # Split content by lines to fit on PDF\n",
        "    lines = content.split('\\n')\n",
        "    for line in lines:\n",
        "        textobject.textLine(line)\n",
        "\n",
        "    c.drawText(textobject)\n",
        "    c.save()\n",
        "    print(f\"Dummy PDF '{filename}' created successfully.\")\n",
        "\n",
        "dummy_resume_content = (\n",
        "    \"John Doe\\n\" \\\n",
        "    \"john.doe@example.com | (123) 456-7890 | LinkedIn: linkedin.com/in/johndoe\\n\\n\" \\\n",
        "    \"Summary\\n\" \\\n",
        "    \"Highly skilled and results-driven Software Engineer with 10 years of experience \" \\\n",
        "    \"in developing robust and scalable web applications. Proficient in Python, Java, \" \\\n",
        "    \"and JavaScript, with extensive experience in cloud platforms (AWS, Azure) and \" \\\n",
        "    \"database management (SQL, NoSQL). Seeking to leverage strong technical expertise \" \\\n",
        "    \"and problem-solving skills to contribute to innovative projects.\\n\\n\" \\\n",
        "    \"Experience\\n\" \\\n",
        "    \"Senior Software Engineer | Tech Solutions Inc. | 2018 - Present\\n\" \\\n",
        "    \"- Led the design and development of a microservices-based e-commerce platform, \" \\\n",
        "    \"  resulting in a 30% improvement in system performance.\\n\" \\\n",
        "    \"- Implemented CI/CD pipelines using Jenkins and Docker, reducing deployment time by 50%.\\n\" \\\n",
        "    \"- Mentored junior engineers and conducted code reviews to ensure high code quality.\\n\\n\" \\\n",
        "    \"Software Engineer | Web Innovators LLC | 2014 - 2018\\n\" \\\n",
        "    \"- Developed and maintained full-stack web applications using Python/Django and React.\\n\" \\\n",
        "    \"- Collaborated with product managers and UX designers to translate requirements into technical specifications.\\n\" \\\n",
        "    \"- Optimized database queries, leading to a 20% reduction in data retrieval times.\\n\\n\" \\\n",
        "    \"Education\\n\" \\\n",
        "    \"M.S. Computer Science | University of Example | 2014\\n\" \\\n",
        "    \"B.S. Computer Science | State University | 2012\\n\\n\" \\\n",
        "    \"Skills\\n\" \\\n",
        "    \"Programming Languages: Python, Java, JavaScript, C++\\n\" \\\n",
        "    \"Web Frameworks: Django, Flask, React, Angular\\n\" \\\n",
        "    \"Cloud Platforms: AWS, Azure, Google Cloud Platform (GCP)\\n\" \\\n",
        "    \"Databases: PostgreSQL, MongoDB, MySQL\\n\" \\\n",
        "    \"Tools & Technologies: Docker, Kubernetes, Jenkins, Git, JIRA\\n\" \\\n",
        "    \"Methodologies: Agile, Scrum\"\n",
        ")\n",
        "\n",
        "create_dummy_pdf(filename=\"dummy_resume.pdf\", content=dummy_resume_content)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reportlab installed successfully.\n",
            "Dummy PDF 'dummy_resume.pdf' created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53445e3f"
      },
      "source": [
        "**Reasoning**:\n",
        "The dummy PDF has been created and `reportlab` is installed. Now I will use the previously defined `extract_text_from_pdf` function to read the content of the `dummy_resume.pdf` file into `resume_text`. I will then define a dummy job description HTML content and save it to a temporary file named `dummy_job_description.html` to simulate a web page, since the provided `job_url` is a placeholder. After creating the dummy HTML file, I'll call the `extract_text_from_url` function to process this local file. Finally, I will print the first 500 characters of both `resume_text` and `job_description_text` to verify the extraction, which fulfills the remaining instructions of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98d22bd9",
        "outputId": "10007ab0-c48a-4057-9634-536c857f73a1"
      },
      "source": [
        "import os\n",
        "\n",
        "# Create a dummy job description HTML file since the job_url is a placeholder.\n",
        "dummy_job_description_html_content = (\n",
        "    \"<html><body><h1>Senior Software Engineer</h1>\"\n",
        "    \"<p>We are looking for a highly motivated Senior Software Engineer to join our team. \"\n",
        "    \"The ideal candidate will have extensive experience in <b>Python, AWS, and Kubernetes</b>. \"\n",
        "    \"Responsibilities include designing and implementing scalable software solutions, \"\n",
        "    \"mentoring junior developers, and contributing to architectural decisions. \"\n",
        "    \"Familiarity with Agile methodologies and CI/CD pipelines is a plus.</p>\"\n",
        "    \"<h2>Requirements</h2>\"\n",
        "    \"<ul>\"\n",
        "    \"<li>10+ years of experience in software development.</li>\"\n",
        "    \"<li>Expertise in Python, Java, or Go.</li>\"\n",
        "    \"<li>Strong knowledge of cloud platforms (AWS, Azure, GCP).</li>\"\n",
        "    \"<li>Experience with containerization (Docker, Kubernetes).</li>\"\n",
        "    \"<li>Excellent problem-solving and communication skills.</li>\"\n",
        "    \"</ul>\"\n",
        "    \"</body></html>\"\n",
        ")\n",
        "\n",
        "dummy_job_html_file = \"dummy_job_description.html\"\n",
        "with open(dummy_job_html_file, \"w\") as f:\n",
        "    f.write(dummy_job_description_html_content)\n",
        "print(f\"Dummy job description HTML file '{dummy_job_html_file}' created.\")\n",
        "\n",
        "# Update job_url to point to the local dummy HTML file\n",
        "# This is a workaround since direct web scraping of a placeholder URL is not feasible.\n",
        "job_url_local = f\"file://{os.path.abspath(dummy_job_html_file)}\"\n",
        "\n",
        "\n",
        "# Extract text from the dummy PDF resume\n",
        "resume_text = extract_text_from_pdf(resume_path)\n",
        "print(f\"Extracted text from resume (first 500 chars):\\n{resume_text[:500]}...\")\n",
        "\n",
        "# Extract text from the dummy job description (using the local HTML file workaround)\n",
        "# The extract_text_from_url function is designed for http/https, but we can make a local path work by reading the file directly\n",
        "# For demonstration, we will read the local dummy HTML file directly\n",
        "with open(dummy_job_html_file, 'r') as f:\n",
        "    dummy_html_content = f.read()\n",
        "\n",
        "# Use BeautifulSoup to parse the local HTML content\n",
        "soup = BeautifulSoup(dummy_html_content, 'html.parser')\n",
        "for script_or_style in soup(['script', 'style']):\n",
        "    script_or_style.extract()\n",
        "text = soup.get_text()\n",
        "lines = (line.strip() for line in text.splitlines())\n",
        "chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
        "job_description_text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
        "\n",
        "print(f\"Extracted text from job description (first 500 chars):\\n{job_description_text[:500]}...\")\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy job description HTML file 'dummy_job_description.html' created.\n",
            "Extracted text from resume (first 500 chars):\n",
            "John Doe\n",
            "john.doe@example.com | (123) 456-7890 | LinkedIn: linkedin.com/in/johndoe\n",
            "Summary\n",
            "Highly skilled and results-driven Software Engineer with 10 years of experience in developing robust and scalable web applications. Proficient in Python, Java, and JavaScript, with extensive experience in cloud platforms (AWS, Azure) and database management (SQL, NoSQL). Seeking to leverage strong technical expertise and problem-solving skills to contribute to innovative projects.\n",
            "Experience\n",
            "Senior Softwar...\n",
            "Extracted text from job description (first 500 chars):\n",
            "Senior Software EngineerWe are looking for a highly motivated Senior Software Engineer to join our team. The ideal candidate will have extensive experience in Python, AWS, and Kubernetes. Responsibilities include designing and implementing scalable software solutions, mentoring junior developers, and contributing to architectural decisions. Familiarity with Agile methodologies and CI/CD pipelines is a plus.Requirements10+ years of experience in software development.Expertise in Python, Java, or ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "553beb35"
      },
      "source": [
        "## Develop `analyze_skills_and_gaps` function\n",
        "\n",
        "### Subtask:\n",
        "Create a new function that takes extracted resume text and job description text as input, uses the Gemini 2.5 Flash model to identify skills from both sources, compare them, and generate a skills gap analysis report. It should clearly outline missing skills.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f70df3a5"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to define the `analyze_skills_and_gaps` function as instructed, which will construct a prompt for the LLM, call the `llm_model.generate_content()` method, and return the generated analysis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "981990ef",
        "outputId": "2ca32e27-2224-4ddd-8376-3e9a63e73532"
      },
      "source": [
        "def analyze_skills_and_gaps(resume_text: str, job_description_text: str) -> str:\n",
        "    \"\"\"Analyzes a candidate's resume against a job description using the LLM to identify skills and gaps.\"\"\"\n",
        "    prompt = f\"\"\"You are an expert HR analyst. Your task is to compare a candidate's resume with a job description.\n",
        "\n",
        "Here is the candidate's Resume:\n",
        "---\\n{resume_text}\\n---\n",
        "\n",
        "Here is the Job Description:\n",
        "---\\n{job_description_text}\\n---\n",
        "\n",
        "Please perform the following steps and provide your output in a structured, easy-to-read format:\n",
        "\n",
        "1.  **Extract Candidate Skills**: List all key technical and soft skills explicitly mentioned in the resume.\n",
        "2.  **Extract Required Job Skills**: List all essential technical and soft skills mentioned in the job description.\n",
        "3.  **Skills Comparison**: Compare the two lists and identify:\n",
        "    *   **Matched Skills**: Skills present in both the resume and the job description.\n",
        "    *   **Missing Skills (Gaps)**: Skills required by the job description but NOT found in the resume.\n",
        "    *   **Additional Skills**: Skills present in the resume but not explicitly required by the job description.\n",
        "4.  **Overall Fit Summary**: Provide a brief summary of how well the candidate's skills align with the job requirements, highlighting their strengths and areas for development based on the identified gaps.\n",
        "\n",
        "Ensure your output is clear, concise, and structured, using bullet points for lists where appropriate.\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Assuming llm_model is already loaded from previous steps\n",
        "        if llm_model is None:\n",
        "            return \"Error: LLM model not initialized.\"\n",
        "\n",
        "        response = llm_model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Error during LLM analysis: {e}\"\n",
        "\n",
        "print(\"Function `analyze_skills_and_gaps` defined.\")\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function `analyze_skills_and_gaps` defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dca9857"
      },
      "source": [
        "**Reasoning**:\n",
        "The `analyze_skills_and_gaps` function has been defined. Now, I need to replace the placeholder implementation of `analyze_resume_job_description_placeholder` with a call to the newly defined `analyze_skills_and_gaps` function. This will integrate the LLM-based analysis into the `candidate_agent`'s tool, allowing the `root_agent` to orchestrate the full workflow.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea486296",
        "outputId": "841fd009-d1e6-40b5-b138-ebb9d695ce95"
      },
      "source": [
        "import asyncio\n",
        "import nest_asyncio\n",
        "import random\n",
        "import re # Import regex for salary parsing\n",
        "\n",
        "# Ensure nest_asyncio is applied if not already done in the session\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Assuming Tool, Agent are defined in previous cells and are available in scope.\n",
        "# Re-defining them here for clarity in this single block if notebook state is reset\n",
        "class Tool:\n",
        "    def __init__(self, func, name, description):\n",
        "        self.func = func\n",
        "        self.name = name\n",
        "        self.description = description\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, name, instruction, tools: list):\n",
        "        self.name = name\n",
        "        self.instruction = instruction\n",
        "        self.tools = tools\n",
        "\n",
        "# Helper function to parse salary from string\n",
        "def parse_salary(salary_str: str) -> int:\n",
        "    if not salary_str: return 0\n",
        "    # Remove non-numeric characters except comma, then remove comma, then convert to int\n",
        "    numeric_str = re.sub(r'[^\\\\d,]', '', salary_str)\n",
        "    numeric_str = numeric_str.replace(',', '')\n",
        "    try:\n",
        "        return int(numeric_str)\n",
        "    except ValueError:\n",
        "        return 0\n",
        "\n",
        "# NOTE: The analyze_skills_and_gaps function from the previous step is now fully implemented.\n",
        "# It will be called by the analysis tool below.\n",
        "\n",
        "def analyze_skills_and_gaps(resume_text: str, job_description_text: str) -> str:\n",
        "    \"\"\"Analyzes a candidate's resume against a job description using the LLM to identify skills and gaps.\"\"\"\n",
        "    prompt = f\"\"\"You are an expert HR analyst. Your task is to compare a candidate's resume with a job description.\n",
        "\n",
        "Here is the candidate's Resume:\n",
        "---\n",
        "{resume_text}\\n---\n",
        "\n",
        "Here is the Job Description:\n",
        "---\n",
        "{job_description_text}\\n---\n",
        "\n",
        "Please perform the following steps and provide your output in a structured, easy-to-read format:\n",
        "\n",
        "1.  **Extract Candidate Skills**: List all key technical and soft skills explicitly mentioned in the resume.\n",
        "2.  **Extract Required Job Skills**: List all essential technical and soft skills mentioned in the job description.\n",
        "3.  **Skills Comparison**: Compare the two lists and identify:\n",
        "    *   **Matched Skills**: Skills present in both the resume and the job description.\n",
        "    *   **Missing Skills (Gaps)**: Skills required by the job description but NOT found in the resume.\n",
        "    *   **Additional Skills**: Skills present in the resume but not explicitly required by the job description.\n",
        "4.  **Overall Fit Summary**: Provide a brief summary of how well the candidate's skills align with the job requirements, highlighting their strengths and areas for development based on the identified gaps.\n",
        "\n",
        "Ensure your output is clear, concise, and structured, using bullet points for lists where appropriate.\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Assuming llm_model is already loaded from previous steps\n",
        "        global llm_model # Declare llm_model as global to access it\n",
        "        if llm_model is None:\n",
        "            return \"Error: LLM model not initialized.\"\n",
        "\n",
        "        response = llm_model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Error during LLM analysis: {e}\"\n",
        "\n",
        "# Update the analysis function to call the LLM-based logic\n",
        "def analyze_resume_job_description_full(resume_text: str, job_description_text: str) -> dict:\n",
        "    \"\"\"Performs a full resume and job description analysis using the LLM.\n",
        "    This function replaces the placeholder and calls analyze_skills_and_gaps.\n",
        "    \"\"\"\n",
        "    print(f\"Initiating LLM-based analysis for resume (length: {len(resume_text)}) and job description (length: {len(job_description_text)}).\")\n",
        "    analysis_report = analyze_skills_and_gaps(resume_text, job_description_text)\n",
        "\n",
        "    if \"Error during LLM analysis\" in analysis_report:\n",
        "        return {\"analysis_status\": \"failure\", \"message\": analysis_report}\n",
        "    else:\n",
        "        return {\"analysis_status\": \"success\", \"message\": \"LLM-based analysis completed.\", \"report\": analysis_report}\n",
        "\n",
        "# 1. No modifications to Tool and Agent class structures are needed at this stage.\n",
        "\n",
        "# 2. Remove instantiation of old tools and agents.\n",
        "# job_search_tool, submit_application_tool, job_search_agent, and the original candidate_agent are removed.\n",
        "\n",
        "# 3. Define a new Tool instance for analysis.\n",
        "analysis_tool = Tool(\n",
        "    func=analyze_resume_job_description_full, # Use the full analysis function\n",
        "    name=\"analyze_resume_job_description\",\n",
        "    description=\"Analyzes a candidate's resume against a job description to identify skills and gaps using an LLM.\"\n",
        ")\n",
        "\n",
        "# 4. Re-instantiate the candidate_agent with the new analysis_tool.\n",
        "candidate_agent = Agent(\n",
        "    name=\"candidate_agent\",\n",
        "    instruction=\"I manage candidate profiles and analyze resumes against job descriptions.\",\n",
        "    tools=[analysis_tool]\n",
        ")\n",
        "\n",
        "# Redefine CoordinatorAgent to reflect new workflow\n",
        "class CoordinatorAgent(Agent):\n",
        "    def __init__(self, name: str, instruction: str, tools: list = None, sub_agents: list = None):\n",
        "        super().__init__(name, instruction, tools if tools is not None else [])\n",
        "        self.sub_agents = sub_agents if sub_agents is not None else []\n",
        "\n",
        "    async def run_live(self, resume_text: str, job_description_text: str):\n",
        "        yield f\"üöÄ CoordinatorAgent '{self.name}' initiating resume and job description analysis...\"\n",
        "\n",
        "        candidate_agent_found = next((agent for agent in self.sub_agents if agent.name == \"candidate_agent\"), None)\n",
        "        if not candidate_agent_found:\n",
        "            yield \"‚ùå Error: candidate_agent not found.\"\n",
        "            return\n",
        "\n",
        "        analysis_tool_instance = next((tool for tool in candidate_agent_found.tools if tool.name == \"analyze_resume_job_description\"), None)\n",
        "        if not analysis_tool_instance:\n",
        "            yield \"‚ùå Error: analyze_resume_job_description tool not found for candidate_agent.\"\n",
        "            return\n",
        "\n",
        "        yield f\"‚öôÔ∏è Delegating analysis to {candidate_agent_found.name} using {analysis_tool_instance.name} tool...\"\n",
        "        try:\n",
        "            analysis_result = analysis_tool_instance.func(resume_text, job_description_text)\n",
        "            if analysis_result.get('analysis_status') == 'success':\n",
        "                yield f\"‚úÖ Analysis complete: {analysis_result.get('message', 'No message provided.')}\"\n",
        "                yield \"--- LLM Analysis Report ---\"\n",
        "                yield analysis_result.get('report', 'No report content available.')\n",
        "                yield \"---------------------------\"\n",
        "            else:\n",
        "                yield f\"‚ùå Analysis failed: {analysis_result.get('message', 'Unknown error.')}\"\n",
        "        except Exception as e:\n",
        "            yield f\"‚ùå Error during analysis: {e}\"\n",
        "            return\n",
        "\n",
        "# Re-instantiate the CoordinatorAgent with the new class definition and updated sub-agents\n",
        "root_agent = CoordinatorAgent(\n",
        "    name=\"root_agent\",\n",
        "    instruction=\"I orchestrate the resume and job description analysis process.\",\n",
        "    sub_agents=[candidate_agent]\n",
        ")\n",
        "\n",
        "print(\"Agent and Tool definitions updated for new workflow and analysis logic integrated.\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent and Tool definitions updated for new workflow and analysis logic integrated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f04cd089"
      },
      "source": [
        "## Run the new workflow\n",
        "\n",
        "### Subtask:\n",
        "Call the updated `CoordinatorAgent.run_live` method with the sample `resume_path` and `job_url` to demonstrate the new workflow and display the output.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3cfb477"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to define an asynchronous function to run the `CoordinatorAgent.run_live` method, iterate through its yielded outputs, and then execute this function using `asyncio.run` with the extracted resume and job description texts to demonstrate the new workflow.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95dd04fa",
        "outputId": "03400881-1336-409e-f3ee-34f9601504bb"
      },
      "source": [
        "async def run_analysis_workflow(resume_text: str, job_description_text: str):\n",
        "    \"\"\"Runs the resume and job description analysis workflow.\"\"\"\n",
        "    print(\"\\nStarting skills gap analysis workflow...\")\n",
        "    async for step_output in root_agent.run_live(resume_text, job_description_text):\n",
        "        print(step_output)\n",
        "    print(\"Skills gap analysis workflow completed.\")\n",
        "\n",
        "# Run the workflow with the extracted texts\n",
        "if __name__ == '__main__':\n",
        "    # Ensure an event loop is running. nest_asyncio.apply() usually handles this for Colab.\n",
        "    asyncio.run(run_analysis_workflow(resume_text, job_description_text))\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting skills gap analysis workflow...\n",
            "üöÄ CoordinatorAgent 'root_agent' initiating resume and job description analysis...\n",
            "‚öôÔ∏è Delegating analysis to candidate_agent using analyze_resume_job_description tool...\n",
            "Initiating LLM-based analysis for resume (length: 1592) and job description (length: 662).\n",
            "‚ùå Analysis failed: Error during LLM analysis: 'Model' object has no attribute 'generate_content'\n",
            "Skills gap analysis workflow completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "580b3cd8"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous execution failed because the `llm_model` object did not have a `generate_content` method. This indicates that `gen.get_model()` was used instead of `gen.GenerativeModel()` to instantiate the LLM. I need to re-initialize the LLM model using `gen.GenerativeModel()` so that it can correctly generate content. This change will be applied to the relevant code block where `llm_model` was originally set up.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fd79ffc",
        "outputId": "900a37f6-fe21-41ac-faeb-520feefb01bf"
      },
      "source": [
        "import google.generativeai as gen\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import PyPDF2\n",
        "import os\n",
        "\n",
        "# Configure the Google Generative AI client\n",
        "# Make sure to set your GOOGLE_API_KEY in your environment variables or provide it when prompted.\n",
        "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
        "\n",
        "if not GOOGLE_API_KEY or GOOGLE_API_KEY == \"YOUR_GOOGLE_API_KEY_HERE\":\n",
        "    print(\"GOOGLE_API_KEY environment variable not set or is a placeholder.\")\n",
        "    print(\"Please provide your Google API Key to continue.\")\n",
        "    GOOGLE_API_KEY = input(\"Enter your Google API Key: \").strip()\n",
        "\n",
        "    # Optionally, set it as an environment variable for subsequent runs in this session\n",
        "    if GOOGLE_API_KEY:\n",
        "        os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "    else:\n",
        "        raise ValueError(\"Google API Key is required but was not provided.\")\n",
        "\n",
        "gen.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "llm_model = None\n",
        "tried_model_names = ['gemini-1.5-flash', 'gemini-pro', 'gemini-1.0-pro']\n",
        "\n",
        "for model_name in tried_model_names:\n",
        "    try:\n",
        "        # Correctly instantiate GenerativeModel\n",
        "        llm_model = gen.GenerativeModel(model_name)\n",
        "        print(f\"Successfully loaded LLM model: {llm_model.model_name}\")\n",
        "        break # Exit loop if a model is successfully loaded\n",
        "    except Exception as e:\n",
        "        print(f\"WARNING: Could not load model '{model_name}': {e}\")\n",
        "\n",
        "if not llm_model:\n",
        "    print(\"Attempting to list available models to find an alternative...\")\n",
        "    try:\n",
        "        # Filter for models that support text generation\n",
        "        available_generative_models = [m.name for m in gen.list_models() if \"generateContent\" in m.supported_generation_methods]\n",
        "        if available_generative_models:\n",
        "            print(f\"Available generative models: {', '.join(available_generative_models)}\")\n",
        "            # Try to pick the first available generative model as a fallback\n",
        "            fallback_model_name = available_generative_models[0]\n",
        "            print(f\"Attempting to load fallback model: {fallback_model_name}\")\n",
        "            # Correctly instantiate GenerativeModel for fallback\n",
        "            llm_model = gen.GenerativeModel(fallback_model_name)\n",
        "            print(f\"Successfully loaded fallback LLM model: {llm_model.model_name}\")\n",
        "        else:\n",
        "            raise ValueError(\"No generative models found with the provided API key that support 'generateContent'.\")\n",
        "    except Exception as list_e:\n",
        "        raise ValueError(f\"Error listing models or no fallback model found: {list_e}. Please check your API key and region settings for Google Generative AI access.\")\n",
        "\n",
        "if llm_model:\n",
        "    print(\"Imports and Google Generative AI client configured successfully.\")\n",
        "else:\n",
        "    raise ValueError(\"Failed to load any LLM model after multiple attempts. Please ensure your GOOGLE_API_KEY is valid and has access to Google Generative AI models in your region.\")\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded LLM model: models/gemini-1.5-flash\n",
            "Imports and Google Generative AI client configured successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "012b5b18"
      },
      "source": [
        "**Reasoning**:\n",
        "The LLM model has been successfully re-initialized with `gen.GenerativeModel()`. Now, I need to re-run the `run_analysis_workflow` to ensure the `analyze_skills_and_gaps` function correctly calls the LLM's `generate_content` method and produces the expected analysis report.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "f06ad225",
        "outputId": "04c12869-1565-41b7-dde3-b5034d37bb5b"
      },
      "source": [
        "async def run_analysis_workflow(resume_text: str, job_description_text: str):\n",
        "    \"\"\"Runs the resume and job description analysis workflow.\"\"\"\n",
        "    print(\"\\nStarting skills gap analysis workflow...\")\n",
        "    async for step_output in root_agent.run_live(resume_text, job_description_text):\n",
        "        print(step_output)\n",
        "    print(\"Skills gap analysis workflow completed.\")\n",
        "\n",
        "# Run the workflow with the extracted texts\n",
        "if __name__ == '__main__':\n",
        "    # Ensure an event loop is running. nest_asyncio.apply() usually handles this for Colab.\n",
        "    asyncio.run(run_analysis_workflow(resume_text, job_description_text))\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting skills gap analysis workflow...\n",
            "üöÄ CoordinatorAgent 'root_agent' initiating resume and job description analysis...\n",
            "‚öôÔ∏è Delegating analysis to candidate_agent using analyze_resume_job_description tool...\n",
            "Initiating LLM-based analysis for resume (length: 1592) and job description (length: 662).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:404 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 310.14ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùå Analysis failed: Error during LLM analysis: 404 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
            "Skills gap analysis workflow completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8303d94d"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to run the analysis workflow failed because the model 'gemini-1.5-flash' was not found or not supported for `generateContent` despite being 'successfully loaded' in an earlier step. This indicates that the initial model loading logic was not robust enough to ensure the chosen model is truly functional for content generation. To fix this, I will update the LLM initialization to explicitly select 'models/gemini-2.5-flash' (as identified in the `available_generative_models` from the kernel state and requested in the original task as 'Gemini 2.5 Flash'). If 'models/gemini-2.5-flash' is not available for content generation, it will fall back to the first model returned by `gen.list_models()` that supports `generateContent`, ensuring a functional model is always loaded.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "8b00ce85",
        "outputId": "2e26f811-5c21-4981-c165-26bcf1c93da6"
      },
      "source": [
        "import google.generativeai as gen\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import PyPDF2\n",
        "import os\n",
        "\n",
        "# Configure the Google Generative AI client\n",
        "# Make sure to set your GOOGLE_API_KEY in your environment variables or provide it when prompted.\n",
        "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
        "\n",
        "if not GOOGLE_API_KEY or GOOGLE_API_KEY == \"YOUR_GOOGLE_API_KEY_HERE\":\n",
        "    print(\"GOOGLE_API_KEY environment variable not set or is a placeholder.\")\n",
        "    print(\"Please provide your Google API Key to continue.\")\n",
        "    GOOGLE_API_KEY = input(\"Enter your Google API Key: \").strip()\n",
        "\n",
        "    # Optionally, set it as an environment variable for subsequent runs in this session\n",
        "    if GOOGLE_API_KEY:\n",
        "        os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "    else:\n",
        "        raise ValueError(\"Google API Key is required but was not provided.\")\n",
        "\n",
        "gen.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "llm_model = None\n",
        "\n",
        "print(\"Attempting to find and load a suitable generative model...\")\n",
        "try:\n",
        "    # Get all models that support text generation\n",
        "    available_generative_models = [m.name for m in gen.list_models() if \"generateContent\" in m.supported_generation_methods]\n",
        "    if not available_generative_models:\n",
        "        raise ValueError(\"No generative models found with the provided API key that support 'generateContent'.\")\n",
        "\n",
        "    chosen_model_name = None\n",
        "    # Prioritize 'gemini-2.5-flash' as per the subtask instruction if available\n",
        "    if 'models/gemini-2.5-flash' in available_generative_models:\n",
        "        chosen_model_name = 'models/gemini-2.5-flash'\n",
        "    # Fallback to 'gemini-1.5-flash' if 'gemini-2.5-flash' is not available (though it failed previously, it's worth re-checking availability)\n",
        "    elif 'models/gemini-1.5-flash' in available_generative_models:\n",
        "        chosen_model_name = 'models/gemini-1.5-flash'\n",
        "    else:\n",
        "        # Fallback to the first available generative model if neither specific flash model is found\n",
        "        chosen_model_name = available_generative_models[0]\n",
        "\n",
        "    print(f\"Loading LLM model: {chosen_model_name}\")\n",
        "    llm_model = gen.GenerativeModel(chosen_model_name)\n",
        "    print(f\"Successfully loaded LLM model: {llm_model.model_name}\")\n",
        "\n",
        "except Exception as e:\n",
        "    raise ValueError(f\"Error during LLM model loading: {e}. Please check your API key and region settings for Google Generative AI access.\")\n",
        "\n",
        "if llm_model:\n",
        "    print(\"Imports and Google Generative AI client configured successfully.\")\n",
        "else:\n",
        "    raise ValueError(\"Failed to load any LLM model. This should not happen if the previous block passed.\")\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to find and load a suitable generative model...\n",
            "Loading LLM model: models/gemini-2.5-flash\n",
            "Successfully loaded LLM model: models/gemini-2.5-flash\n",
            "Imports and Google Generative AI client configured successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaaedafc"
      },
      "source": [
        "**Reasoning**:\n",
        "The LLM model has now been successfully loaded with `models/gemini-2.5-flash`, which is a functional generative model. I need to re-run the `run_analysis_workflow` to verify that the `analyze_skills_and_gaps` function correctly calls the LLM's `generate_content` method and produces the expected analysis report, now that the model issue is resolved.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "556bdf7b",
        "outputId": "21439efe-98bf-437b-df9c-390ddf953892"
      },
      "source": [
        "async def run_analysis_workflow(resume_text: str, job_description_text: str):\n",
        "    \"\"\"Runs the resume and job description analysis workflow.\"\"\"\n",
        "    print(\"\\nStarting skills gap analysis workflow...\")\n",
        "    async for step_output in root_agent.run_live(resume_text, job_description_text):\n",
        "        print(step_output)\n",
        "    print(\"Skills gap analysis workflow completed.\")\n",
        "\n",
        "# Run the workflow with the extracted texts\n",
        "if __name__ == '__main__':\n",
        "    # Ensure an event loop is running. nest_asyncio.apply() usually handles this for Colab.\n",
        "    asyncio.run(run_analysis_workflow(resume_text, job_description_text))\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting skills gap analysis workflow...\n",
            "üöÄ CoordinatorAgent 'root_agent' initiating resume and job description analysis...\n",
            "‚öôÔ∏è Delegating analysis to candidate_agent using analyze_resume_job_description tool...\n",
            "Initiating LLM-based analysis for resume (length: 1592) and job description (length: 662).\n",
            "‚úÖ Analysis complete: LLM-based analysis completed.\n",
            "--- LLM Analysis Report ---\n",
            "Here's the comparison of John Doe's resume with the Senior Software Engineer job description:\n",
            "\n",
            "---\n",
            "\n",
            "### 1. Extract Candidate Skills\n",
            "\n",
            "**Technical Skills:**\n",
            "*   **Experience:** 10 years in software development, Senior Software Engineer, Software Engineer\n",
            "*   **Programming Languages:** Python, Java, JavaScript, C++\n",
            "*   **Web Frameworks:** Django, Flask, React, Angular\n",
            "*   **Cloud Platforms:** AWS, Azure, Google Cloud Platform (GCP)\n",
            "*   **Databases:** PostgreSQL, MongoDB, MySQL (SQL, NoSQL)\n",
            "*   **Tools & Technologies:** Docker, Kubernetes, Jenkins, Git, JIRA, Microservices\n",
            "*   **Development Practices:** CI/CD pipelines, Full-stack web applications, Scalable web applications, Database query optimization, Code reviews\n",
            "\n",
            "**Soft Skills & Methodologies:**\n",
            "*   Problem-solving\n",
            "*   Leadership (led design, mentored junior engineers)\n",
            "*   Mentoring junior engineers\n",
            "*   Collaboration (with product managers, UX designers)\n",
            "*   Agile, Scrum\n",
            "*   Results-driven\n",
            "*   Strong technical expertise\n",
            "\n",
            "### 2. Extract Required Job Skills\n",
            "\n",
            "**Technical Skills:**\n",
            "*   **Experience:** 10+ years in software development (Senior Software Engineer role)\n",
            "*   **Key Technologies:** Python (extensive experience), AWS (extensive experience), Kubernetes (extensive experience)\n",
            "*   **Programming Languages:** Expertise in Python, Java, *or* Go\n",
            "*   **Cloud Platforms:** Strong knowledge of cloud platforms (AWS, Azure, GCP)\n",
            "*   **Containerization:** Experience with Docker, Kubernetes\n",
            "*   **Development Practices:** Designing and implementing scalable software solutions, CI/CD pipelines (plus), Contributing to architectural decisions\n",
            "\n",
            "**Soft Skills & Methodologies:**\n",
            "*   Mentoring junior developers\n",
            "*   Agile methodologies (plus)\n",
            "*   Excellent problem-solving skills\n",
            "*   Excellent communication skills\n",
            "*   Highly motivated\n",
            "\n",
            "### 3. Skills Comparison\n",
            "\n",
            "**Matched Skills:**\n",
            "*   **Experience:** 10+ years in software development (Candidate has 10 years as Senior/Software Engineer)\n",
            "*   **Core Technologies:** Python, AWS, Kubernetes\n",
            "*   **Programming Language:** Java (meets the \"Java OR Go\" requirement)\n",
            "*   **Cloud Platforms:** AWS, Azure, GCP\n",
            "*   **Containerization:** Docker, Kubernetes\n",
            "*   **Scalable Solutions:** Designing and implementing scalable software solutions (demonstrated by leading microservices platform design)\n",
            "*   **CI/CD Pipelines:** Implemented CI/CD pipelines\n",
            "*   **Mentoring:** Mentoring junior developers\n",
            "*   **Methodologies:** Agile methodologies\n",
            "*   **Soft Skills:** Problem-solving skills\n",
            "\n",
            "**Missing Skills (Gaps):**\n",
            "*   **Go:** While Java covers the requirement, Go is not present if it were a preference. (Not a critical gap due to Java expertise)\n",
            "*   **Contributing to architectural decisions:** Explicitly mentioned in the job, although implied by the candidate's experience leading design.\n",
            "*   **Excellent communication skills:** Explicitly mentioned in the job, though likely demonstrated through mentoring and collaboration, it's not explicitly listed as an \"excellent\" skill.\n",
            "*   **Highly motivated:** A soft skill, generally assessed through interview rather than explicitly listed.\n",
            "\n",
            "**Additional Skills (Present in Resume, Not Explicitly Required by JD):**\n",
            "*   **Programming Languages:** JavaScript, C++\n",
            "*   **Web Frameworks:** Django, Flask, React, Angular\n",
            "*   **Databases:** PostgreSQL, MongoDB, MySQL (SQL, NoSQL)\n",
            "*   **Tools & Technologies:** Jenkins, Git, JIRA, Microservices (though implied by scalable solutions)\n",
            "*   **Development Practices:** Full-stack web development, Database query optimization, Code reviews\n",
            "*   **Methodologies:** Scrum\n",
            "\n",
            "### 4. Overall Fit Summary\n",
            "\n",
            "John Doe is an exceptionally strong candidate for the Senior Software Engineer position. He perfectly aligns with the core technical requirements, including 10+ years of experience, extensive proficiency in Python, AWS, and Kubernetes, and strong knowledge of various cloud platforms and containerization. His background in leading design, implementing CI/CD pipelines, and mentoring junior engineers directly matches the key responsibilities and desired qualities. The candidate's expertise in Java also successfully covers the job's \"Java or Go\" language requirement.\n",
            "\n",
            "While \"contributing to architectural decisions\" and \"excellent communication skills\" are explicitly mentioned in the job description but not as direct keywords on the resume, John's resume strongly implies these through his leadership roles (leading design of a microservices platform) and mentoring experience. These would likely be areas to highlight further during an interview.\n",
            "\n",
            "Overall, John Doe presents an excellent fit, demonstrating a robust and comprehensive skill set that very closely matches the demands of this Senior Software Engineer role.\n",
            "---------------------------\n",
            "Skills gap analysis workflow completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04d55593"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the successful implementation of the new workflow, including resume analysis, job description comparison, and skills gap identification using Gemini 2.5 Flash.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eec3d87a"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The workflow successfully replaced the previous job search and application submission functionality with a resume analysis and skills gap identification process.\n",
        "*   Initial setup required the installation of `PyPDF2` for PDF text extraction.\n",
        "*   Configuring the Google Generative AI client faced challenges, including missing API key environment variables and `NotFound` errors for specific Gemini models (e.g., `gemini-1.5-flash`, `gemini-pro`). This was resolved by implementing a robust model loading strategy that lists available models and prioritizes `models/gemini-2.5-flash`.\n",
        "*   Dummy `resume_path` (PDF) and `job_url` (HTML) inputs were successfully created and processed to extract text content, demonstrating the data ingestion capabilities.\n",
        "*   The `Agent` and `Tool` definitions were updated, removing old functionalities and introducing a new `analysis_tool` integrated into the `candidate_agent` for resume and job description comparison.\n",
        "*   A core `analyze_skills_and_gaps` function was developed, leveraging the Gemini 2.5 Flash model through a structured prompt to identify candidate skills, required job skills, matched skills, missing skills (gaps), and provide an overall fit summary.\n",
        "*   The complete workflow, orchestrated by the `CoordinatorAgent`, successfully executed the analysis, producing a detailed LLM-generated report highlighting skill matches and gaps.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The implemented workflow provides a valuable automated solution for initial candidate screening by rapidly identifying critical skills gaps using an advanced LLM, thereby streamlining the recruitment process.\n",
        "*   To enhance the workflow, consider parsing the LLM's structured output (e.g., into JSON format) to enable programmatic access to identified skills and gaps. This would allow for more advanced filtering, visualization, and integration with other HR systems.\n"
      ]
    }
  ]
}